{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECG_GSR_RESPFeatureCode_Archive.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMM981sPQvfOZbcvLuyWYXq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rmwvamp/ECGNotebooks/blob/main/ECG_GSR_RESPFeatureCode_Archive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdIYYRK1gCPG"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Fri Oct 16 11:08:58 2020\n",
        "\n",
        "@author: rajde\n",
        "\"\"\"\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import signal\n",
        "import peakutils\n",
        "from scipy.signal import find_peaks, peak_widths, peak_prominences\n",
        "import matplotlib.pyplot as plt\n",
        "import biosppy\n",
        "from hrvanalysis import get_time_domain_features, get_frequency_domain_features\n",
        "from scipy import stats\n",
        "\n",
        "# Function Definations\n",
        "\n",
        "def calculate_sample_rate(dataframe_signal):\n",
        "    time=dataframe_signal['TIME']\n",
        "    time=time*60\n",
        "    d_time=time.diff().mean()\n",
        "    sample_frequency=int(1/d_time)\n",
        "    return int(sample_frequency)\n",
        "def butterworth(dataframe,n,wn):\n",
        "    B, A = signal.butter(n, wn, output='ba')\n",
        "    dataframe = signal.filtfilt(B,A, dataframe)\n",
        "    return dataframe\n",
        "def normalize(dataframe):\n",
        "    minimum=np.min(dataframe)\n",
        "    maximum=np.max(dataframe)\n",
        "    dataframe=(dataframe-minimum)/(maximum-minimum)\n",
        "    return dataframe\n",
        "def find_range(array_data):\n",
        "    print(len(array_data))\n",
        "    if(len(array_data)>0):\n",
        "        range_data=abs(np.max(array_data)-np.min(array_data))\n",
        "    if(len(array_data)==0):\n",
        "        range_data=0\n",
        "    return range_data\n",
        "def data_reduce(filename):\n",
        "    temp=pd.read_csv(filename,skiprows=[1])\n",
        "    temp.columns=['TIME','ECG','EMG','F_GSR','H_GSR','HR','MARKER','RESP']\n",
        "    temp=temp.drop(['EMG','MARKER'],axis=1)\n",
        "    return temp\n",
        "def get_slope_intercept(resp):\n",
        "    if(len(resp)==0):\n",
        "        return 0,0,0,0\n",
        "    else:\n",
        "        return stats.theilslopes(resp, np.arange(len(resp)), 0.90) \n",
        "def data_cleanse(filename,frequency_fgsr,frequency_hgsr,frequency_ecg,frequency_resp):\n",
        "    # Reduce Dataset\n",
        "    dataframe=data_reduce(filename)\n",
        "    # Calculate Sample Rate\n",
        "    sample_rate=calculate_sample_rate(dataframe)\n",
        "    # Extract Individually\n",
        "    f_gsr=dataframe['F_GSR']\n",
        "    h_gsr=dataframe['H_GSR']\n",
        "    ecg=dataframe['ECG']\n",
        "    resp=dataframe['RESP']\n",
        "    # Extract time and HR to convert to array\n",
        "    time_minutes=dataframe['TIME']\n",
        "    time_minutes=np.asarray(time_minutes)\n",
        "    hr=dataframe['HR']\n",
        "    hr=np.asarray(hr)\n",
        "    # Normalize Individually\n",
        "    f_gsr=normalize(f_gsr)\n",
        "    h_gsr=normalize(h_gsr)\n",
        "    ecg=normalize(ecg)\n",
        "    resp=normalize(resp)\n",
        "    # Low Pass Filtering\n",
        "    cuttoff_fgsr=(2*frequency_fgsr)/sample_rate\n",
        "    cuttoff_hgsr=(2*frequency_hgsr)/sample_rate\n",
        "    cuttoff_ecg=(2*frequency_ecg)/sample_rate\n",
        "    cuttoff_resp=(2*frequency_resp)/sample_rate\n",
        "    variable_sample_fgsr=butterworth(f_gsr,5,cuttoff_fgsr)\n",
        "    variable_sample_hgsr=butterworth(h_gsr,5,cuttoff_hgsr)    \n",
        "    variable_sample_ecg=butterworth(ecg,5,cuttoff_ecg)\n",
        "    variable_sample_resp=butterworth(resp,5,cuttoff_resp) \n",
        "    # Merge and return\n",
        "    clean_signal_frame=pd.DataFrame({\n",
        "        'TIME':time_minutes,\n",
        "        'HR':hr,\n",
        "        'F_GSR':variable_sample_fgsr,\n",
        "        'H_GSR':variable_sample_hgsr,\n",
        "        'ECG':variable_sample_ecg,\n",
        "        'RESP':variable_sample_resp})\n",
        "    return clean_signal_frame\n",
        "\n",
        "def segment_gsr_extraction(segment,key,sample_rate,scl,label):\n",
        "    segment_signal=segment[key]\n",
        "    segment_signal=segment_signal-scl\n",
        "    segment_signal_deriv=np.gradient(segment_signal)\n",
        "    # statistical\n",
        "    mean_signal=[]\n",
        "    var_signal=[]\n",
        "    # peaks\n",
        "    no_peaks=[]\n",
        "    sum_amp_peaks=[]\n",
        "    sum_response_duration=[]\n",
        "    # range_response_duration=[]\n",
        "    mean_peak_prominence=[]\n",
        "    var_peak_prominence=[]\n",
        "    #Extract statistical feature\n",
        "    start=0\n",
        "    end=int(100*(sample_rate))\n",
        "    overlap=int(100*(sample_rate)/2)\n",
        "    while(end<=len(segment_signal)):\n",
        "        mean_signal.append(np.mean(segment_signal[start:end]))\n",
        "        var_signal.append(np.var(segment_signal[start:end]))\n",
        "        start=start+overlap\n",
        "        end=end+overlap\n",
        "    # Extract characteristic feature\n",
        "    start=0\n",
        "    end=int(100*(sample_rate))\n",
        "    overlap=int(100*(sample_rate)/2)\n",
        "    while(end<=len(segment_signal)):\n",
        "        peak_indices, _ = find_peaks(segment_signal_deriv[start:end],0.0001)\n",
        "        gsr_amp=segment_signal_deriv[peak_indices]\n",
        "        no_peaks.append(len(gsr_amp))\n",
        "        sum_amp_peaks.append(sum(gsr_amp))\n",
        "        peak_widths=signal.peak_widths(segment_signal_deriv[start:end],peak_indices)\n",
        "        peak_prominance=signal.peak_prominences(segment_signal_deriv[start:end],peak_indices)\n",
        "        p_widths=peak_widths[0]\n",
        "        p_prom=peak_prominance[0]\n",
        "        sum_response_duration.append(sum(p_widths)*sample_rate)\n",
        "        # range_response_duration.append(find_range(gsr_peak_widths)*sample_rate)\n",
        "        mean_peak_prominence.append(np.mean(p_prom))\n",
        "        var_peak_prominence.append(np.var(p_prom))\n",
        "        start=start+overlap\n",
        "        end=end+overlap\n",
        "    if(key=='F_GSR'):\n",
        "        df_feature=pd.DataFrame({\n",
        "            'MEAN_FGSR':mean_signal,\n",
        "            'VAR_FGSR':var_signal,\n",
        "            '#FPEAKS':no_peaks,\n",
        "            'SUM_PEAKS_FGSR':sum_amp_peaks,\n",
        "            'SUM_RESPONSE_FGSR':sum_response_duration,\n",
        "            # 'RANGE_RESPONSE_GSR':range_response_duration,\n",
        "            'MEAN_PROM_FGSR':mean_peak_prominence,\n",
        "            'VAR_PROM_FGSR':var_peak_prominence})\n",
        "        df_feature['Label']=label\n",
        "        return df_feature\n",
        "    elif(key=='H_GSR'):\n",
        "        df_feature=pd.DataFrame({\n",
        "            'MEAN_HGSR':mean_signal,\n",
        "            'VAR_HGSR':var_signal,\n",
        "            '#HPEAKS':no_peaks,\n",
        "            'SUM_PEAKS_HGSR':sum_amp_peaks,\n",
        "            'SUM_RESPONSE_HGSR':sum_response_duration,\n",
        "            # 'RANGE_RESPONSE_GSR':range_response_duration,\n",
        "            'MEAN_PROM_HGSR':mean_peak_prominence,\n",
        "            'VAR_PROM_HGSR':var_peak_prominence})\n",
        "        df_feature['Label']=label\n",
        "        return df_feature\n",
        "def segment_ecg_extraction(segment,key,sample_rate,label):\n",
        "    segment_signal=segment[key]\n",
        "    # Time Domain Features\n",
        "    nni_ecg=[]\n",
        "    sdnn_ecg=[]\n",
        "    sdsd_ecg=[]\n",
        "    nni_ecg_50=[]\n",
        "    pnni_ecg_50=[]\n",
        "    nni_ecg_20=[]\n",
        "    pnni_ecg_20=[]\n",
        "    rmssd_ecg=[]\n",
        "    range_nni_ecg=[]\n",
        "    cvsd_ecg=[]\n",
        "    cvnni_ecg=[]\n",
        "    mean_hr_ecg=[]\n",
        "    max_hr_ecg=[]\n",
        "    min_hr_ecg=[]\n",
        "    std_hr_ecg=[]\n",
        "    # Frequency Domain Features\n",
        "    lf_ecg=[]\n",
        "    hf_ecg=[]\n",
        "    vlf_ecg=[]\n",
        "    lfhf_ecg=[]\n",
        "    lfnu_ecg=[]\n",
        "    hfnu_ecg=[]\n",
        "    power_ecg=[]\n",
        "    # Extract time domain features\n",
        "    start=0\n",
        "    end=int(100*(sample_rate))\n",
        "    overlap=int(100*(sample_rate)/2)\n",
        "    while(end<=len(segment_signal)):\n",
        "        peak_indices, _ = find_peaks(segment_signal,height=0.65,distance=sample_rate*0.55,width=sample_rate*0.01) \n",
        "        peak_indices=(peak_indices/sample_rate)\n",
        "        print(len(peak_indices))\n",
        "        time_domain_features = get_time_domain_features(peak_indices)\n",
        "        nni_ecg.append(time_domain_features['mean_nni'])\n",
        "        sdnn_ecg.append(time_domain_features['sdnn'])\n",
        "        sdsd_ecg.append(time_domain_features['sdsd'])\n",
        "        nni_ecg_50.append(time_domain_features['nni_50'])\n",
        "        pnni_ecg_50.append(time_domain_features['pnni_20'])\n",
        "        nni_ecg_20.append(time_domain_features['nni_20'])\n",
        "        pnni_ecg_20.append(time_domain_features['pnni_20'])\n",
        "        rmssd_ecg.append(time_domain_features['rmssd'])\n",
        "        range_nni_ecg.append(time_domain_features['range_nni'])\n",
        "        cvsd_ecg.append(time_domain_features['cvsd'])\n",
        "        cvnni_ecg.append(time_domain_features['cvnni'])\n",
        "        mean_hr_ecg.append(time_domain_features['mean_hr'])\n",
        "        max_hr_ecg.append(time_domain_features['max_hr'])\n",
        "        min_hr_ecg.append(time_domain_features['min_hr'])\n",
        "        std_hr_ecg.append(time_domain_features['std_hr'])\n",
        "        frequency_domain_features=get_frequency_domain_features(peak_indices)\n",
        "        lf_ecg.append(frequency_domain_features['lf'])\n",
        "        hf_ecg.append(frequency_domain_features['hf'])\n",
        "        vlf_ecg.append(frequency_domain_features['vlf'])\n",
        "        lfhf_ecg.append(frequency_domain_features['lf_hf_ratio'])\n",
        "        lfnu_ecg.append(frequency_domain_features['lfnu'])\n",
        "        hfnu_ecg.append(frequency_domain_features['hfnu'])\n",
        "        power_ecg.append(frequency_domain_features['total_power'])\n",
        "        start=start+overlap\n",
        "        end=end+overlap\n",
        "    df_feature=pd.DataFrame({\n",
        "        'NNI_ECG':nni_ecg,\n",
        "        'SDNN_ECG':sdnn_ecg,\n",
        "        'SDSD_ECG':sdsd_ecg,\n",
        "        'NNI_ECG_50':nni_ecg_50,\n",
        "        'PNNI_ECG_50':pnni_ecg_50,\n",
        "        'NNI_ECG_20':nni_ecg_20,\n",
        "        'PNNI_ECG_20':pnni_ecg_20,\n",
        "        'RMSSD_ECG':rmssd_ecg,\n",
        "        'RANGE_NNI_ECG':range_nni_ecg,\n",
        "        'CVSD_ECG':cvsd_ecg,\n",
        "        'CVNNI_ECG':cvnni_ecg,\n",
        "        'MEAN_HR_ECG':mean_hr_ecg,\n",
        "        'MAX_HR_ECG':max_hr_ecg,\n",
        "        'MIN_HR_ECG':min_hr_ecg,\n",
        "        'STD_HR_ECG':std_hr_ecg,\n",
        "        'LF_ECG':lf_ecg,\n",
        "        'HF_ECG':hf_ecg,\n",
        "        'VLF_ECG':vlf_ecg,\n",
        "        'LFHF_ECG':lfhf_ecg,\n",
        "        'LFNU_ECG':lfnu_ecg,\n",
        "        'HFNU_ECG':hfnu_ecg,\n",
        "        'POWER_ECG':power_ecg})\n",
        "    df_feature['Label']=label\n",
        "    return df_feature        \n",
        "\n",
        "def segment_resp_extraction(segment,key,sample_rate,label):\n",
        "    segment_signal=segment[key]\n",
        "    # feature variable defination\n",
        "    mean_resp=[]\n",
        "    var_resp=[]\n",
        "    p1_resp=[]\n",
        "    p2_resp=[]\n",
        "    p3_resp=[]\n",
        "    p4_resp=[]\n",
        "    # resp_slope=[]\n",
        "    # resp_intercept=[]\n",
        "    # Extract Features\n",
        "    start=0\n",
        "    end=int(100*(sample_rate))\n",
        "    overlap=int(100*(sample_rate)/2)\n",
        "    while(end<=len(segment_signal)):\n",
        "        mean_resp.append(np.mean(segment_signal[start:end]))\n",
        "        var_resp.append(np.var(segment_signal[start:end]))\n",
        "        freq,psd=signal.periodogram(segment_signal[start:end], 31)\n",
        "        p1_resp.append(biosppy.signals.tools.band_power(freqs=freq,power=psd,frequency=[0,0.1],decibel=True)['avg_power'])\n",
        "        p2_resp.append(biosppy.signals.tools.band_power(freqs=freq,power=psd,frequency=[0.1,0.2],decibel=True)['avg_power'])\n",
        "        p3_resp.append(biosppy.signals.tools.band_power(freqs=freq,power=psd,frequency=[0.2,0.3],decibel=True)['avg_power'])\n",
        "        p4_resp.append(biosppy.signals.tools.band_power(freqs=freq,power=psd,frequency=[0.3,0.4],decibel=True)['avg_power'])\n",
        "        start=start+overlap\n",
        "        end=end+overlap\n",
        "    df_feature=pd.DataFrame({\n",
        "        'MEAN_RESP':mean_resp,\n",
        "        'VAR_RESP':var_resp,\n",
        "        'P1_RESP':p1_resp,\n",
        "        'P2_RESP':p2_resp,\n",
        "        'P3':p3_resp,\n",
        "        'P4':p4_resp})\n",
        "        # 'RESP_SLOPE':resp_slope,\n",
        "        # 'RESP_INTERCEPT':resp_intercept})\n",
        "    df_feature['Label']=label\n",
        "    return df_feature    \n",
        "\n",
        "# Variable and DS initialization\n",
        "rest=[15.13, 15.05, 15.04, 15, 15.66, 15.04, 15.02, 15.01, 15, 15.01]\n",
        "city1=[16, 14.49, 16.23, 12.31, 19.21, 15.3, 15.81, 13.41, 12.54, 16.12]\n",
        "highway1=[7.74, 7.32, 10.96, 7.23, 8.47, 8.66, 7.43, 7.56, 7.24, 7.14]\n",
        "city2=[6.06, 6.53, 9.83, 9.51, 5.2, 5.27, 7.15, 6.5, 5.99, 5.12]\n",
        "highway2=[7.56, 7.64, 7.64, 7.64, 7.06, 7.04, 6.96, 8.06, 6.82, 6.81]\n",
        "city3=[14.96, 12.29, 10.15, 13.43, 13.21, 12.06, 11.72, 11.68, 12.12, 13.91]\n",
        "\n",
        "def feature_extraction(dataframe,ID):\n",
        "    #Segment into 6 sections and label\n",
        "    sample_rate=calculate_sample_rate(dataframe)\n",
        "    rest_end_time=rest[ID]\n",
        "    city1_end_time=rest_end_time+city1[ID]\n",
        "    highway1_end_time=city1_end_time+highway1[ID]\n",
        "    city2_end_time=highway1_end_time+city2[ID]\n",
        "    highway2_end_time=city2_end_time+highway2[ID]\n",
        "    city3_end_time=highway2_end_time+city3[ID]\n",
        "    #Rest segment\n",
        "    rest_segment=dataframe[int(sample_rate*(rest_end_time-5)*60):int(sample_rate*(rest_end_time)*60)]\n",
        "    rest_segment['Label']=0\n",
        "    # City1 segment\n",
        "    city1_segment=dataframe[int(sample_rate*(city1_end_time-5)*60):int(sample_rate*(city1_end_time)*60)]\n",
        "    city1_segment['Label']=2\n",
        "    # Highway1 segment\n",
        "    highway1_segment=dataframe[int(sample_rate*(highway1_end_time-5)*60):int(sample_rate*(highway1_end_time)*60)]\n",
        "    highway1_segment['Label']=1\n",
        "    # City2 segment\n",
        "    city2_segment=dataframe[int(sample_rate*(city2_end_time-5)*60):int(sample_rate*(city2_end_time)*60)]\n",
        "    city2_segment['Label']=2\n",
        "    # Highway2 Segment\n",
        "    highway2_segment=dataframe[int(sample_rate*(highway2_end_time-5)*60):int(sample_rate*(highway2_end_time)*60)]\n",
        "    highway2_segment['Label']=1\n",
        "    # City3 segment\n",
        "    city3_segment=dataframe[int(sample_rate*(city3_end_time-5)*60):int(sample_rate*(city3_end_time)*60)]\n",
        "    city3_segment['Label']=2\n",
        "    # Baseline Conditioning\n",
        "    # feet\n",
        "    fgsr_baseline=rest_segment['F_GSR']\n",
        "    min_scl=np.min(fgsr_baseline)\n",
        "    max_scl=np.max(fgsr_baseline)\n",
        "    scl_mean=np.mean(fgsr_baseline)\n",
        "    fscl=(scl_mean-min_scl)/(max_scl-min_scl)\n",
        "    # hand\n",
        "    hgsr_baseline=rest_segment['H_GSR']\n",
        "    min_scl=np.min(hgsr_baseline)\n",
        "    max_scl=np.max(hgsr_baseline)\n",
        "    scl_mean=np.mean(hgsr_baseline)\n",
        "    hscl=(scl_mean-min_scl)/(max_scl-min_scl)\n",
        "    # Extract F_GSR features for all segments and concatanate\n",
        "    rest_fgsr_feature=segment_gsr_extraction(rest_segment,'F_GSR',sample_rate,fscl,0)\n",
        "    city1_fgsr_feature=segment_gsr_extraction(city1_segment,'F_GSR',sample_rate,fscl,2)\n",
        "    highway1_fgsr_feature=segment_gsr_extraction(highway1_segment,'F_GSR',sample_rate,fscl,1)\n",
        "    city2_fgsr_feature=segment_gsr_extraction(city2_segment,'F_GSR',sample_rate,fscl,2)\n",
        "    highway2_fgsr_feature=segment_gsr_extraction(highway2_segment,'F_GSR',sample_rate,fscl,1)\n",
        "    city3_fgsr_feature=segment_gsr_extraction(city3_segment,'F_GSR',sample_rate,fscl,2)\n",
        "    f_gsr_feature=pd.concat([rest_fgsr_feature,city1_fgsr_feature,highway1_fgsr_feature,\n",
        "                             city2_fgsr_feature,highway2_fgsr_feature,city3_fgsr_feature],axis=0)\n",
        "    print('foot GSR done')\n",
        "    # Extract H_GSR features for all segments and concatenate\n",
        "    rest_hgsr_feature=segment_gsr_extraction(rest_segment,'H_GSR',sample_rate,hscl,0)\n",
        "    city1_hgsr_feature=segment_gsr_extraction(city1_segment,'H_GSR',sample_rate,hscl,2)\n",
        "    highway1_hgsr_feature=segment_gsr_extraction(highway1_segment,'H_GSR',sample_rate,hscl,1)\n",
        "    city2_hgsr_feature=segment_gsr_extraction(city2_segment,'H_GSR',sample_rate,hscl,2)\n",
        "    highway2_hgsr_feature=segment_gsr_extraction(highway2_segment,'H_GSR',sample_rate,hscl,1)\n",
        "    city3_hgsr_feature=segment_gsr_extraction(city3_segment,'H_GSR',sample_rate,hscl,2)\n",
        "    h_gsr_feature=pd.concat([rest_hgsr_feature,city1_hgsr_feature,highway1_hgsr_feature,\n",
        "                             city2_hgsr_feature,highway2_hgsr_feature,city3_hgsr_feature],axis=0)\n",
        "    print('hand GSR done')\n",
        "    # Extract ECG Features for all segments and concatenate\n",
        "    rest_ecg_feature=segment_ecg_extraction(rest_segment,'ECG',sample_rate,0)\n",
        "    city1_ecg_feature=segment_ecg_extraction(city1_segment,'ECG',sample_rate,2)\n",
        "    highway1_ecg_feature=segment_ecg_extraction(highway1_segment,'ECG',sample_rate,1)   \n",
        "    city2_ecg_feature=segment_ecg_extraction(city2_segment,'ECG',sample_rate,2)\n",
        "    highway2_ecg_feature=segment_ecg_extraction(highway2_segment,'ECG',sample_rate,1)\n",
        "    city3_ecg_feature=segment_ecg_extraction(city3_segment,'ECG',sample_rate,2)\n",
        "    ecg_feature=pd.concat([rest_ecg_feature,city1_ecg_feature,highway1_ecg_feature,\n",
        "                             city2_ecg_feature,highway2_ecg_feature,city3_ecg_feature],axis=0)\n",
        "    print('ECG done')\n",
        "    # Extract RESP Features for all segments and concatenate\n",
        "    rest_resp_feature=segment_resp_extraction(rest_segment,'RESP',sample_rate,0)\n",
        "    city1_resp_feature=segment_resp_extraction(city1_segment,'RESP',sample_rate,2)\n",
        "    highway1_resp_feature=segment_resp_extraction(highway1_segment,'RESP',sample_rate,1)   \n",
        "    city2_resp_feature=segment_resp_extraction(city2_segment,'RESP',sample_rate,2)\n",
        "    highway2_resp_feature=segment_resp_extraction(highway2_segment,'RESP',sample_rate,1)\n",
        "    city3_resp_feature=segment_resp_extraction(city3_segment,'RESP',sample_rate,2)\n",
        "    resp_feature=pd.concat([rest_resp_feature,city1_resp_feature,highway1_resp_feature,\n",
        "                             city2_resp_feature,highway2_resp_feature,city3_resp_feature],axis=0)\n",
        "    print('RESP done')\n",
        "    # Concat final features:\n",
        "    labels=f_gsr_feature['Label']\n",
        "    f_gsr_feature=f_gsr_feature.drop(['Label'],axis=1)\n",
        "    h_gsr_feature=h_gsr_feature.drop(['Label'],axis=1)\n",
        "    ecg_feature=ecg_feature.drop(['Label'],axis=1)\n",
        "    resp_feature=resp_feature.drop(['Label'],axis=1)\n",
        "    final_feature=pd.concat([f_gsr_feature,f_gsr_feature,ecg_feature,resp_feature],axis=1)\n",
        "    final_feature['Label']=labels\n",
        "    return final_feature\n",
        "    \n",
        "drive_files=['drive05.csv','drive06.csv','drive07.csv','drive10.csv','drive11.csv','drive12.csv','drive15.csv']\n",
        "id_numbers=[0,1,2,5,6,7,8]\n",
        "\n",
        "for i in range(0,len(drive_files)):\n",
        "    filename=drive_files[i]\n",
        "    ID=id_numbers[i]\n",
        "    temp=feature_extraction(data_cleanse(filename,1,1,40,10),ID)\n",
        "    temp.to_csv('drive_'+str(ID)+'feature.csv')\n",
        "    print('Number', ID, 'done')\n"
      ]
    }
  ]
}